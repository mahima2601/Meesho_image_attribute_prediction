{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9545364,"sourceType":"datasetVersion","datasetId":5815289}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-07T02:10:18.943743Z","iopub.execute_input":"2024-11-07T02:10:18.944652Z","iopub.status.idle":"2024-11-07T02:10:18.948821Z","shell.execute_reply.started":"2024-11-07T02:10:18.944603Z","shell.execute_reply":"2024-11-07T02:10:18.947801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import models, transforms\nfrom PIL import Image\nimport pandas as pd\nimport pickle\nfrom sklearn.preprocessing import LabelEncoder\n\n# Paths\nmain_folder_loc = '/kaggle/input/visual-taxonomy'\nfolder_train = f\"{main_folder_loc}/train_images\"\nfolder_test = f\"{main_folder_loc}/test_images\"\ntrain_attribute = pd.read_csv(f\"{main_folder_loc}/train.csv\")\ntest_attribute = pd.read_csv(f\"{main_folder_loc}/test.csv\")\ncategory_attributes = pd.read_parquet(f\"{main_folder_loc}/category_attributes.parquet\")\nmodel_variant = 'resnet18'\nmain_folder_save_loc = '/kaggle/working'\nmodel_path_template = f\"{main_folder_save_loc}/model_{model_variant}_{{}}_epoch{{}}.pth\"  # Model path template for each epoch\nencoders_path_template = f\"{main_folder_save_loc}/encoders_{model_variant}_{{}}.pkl\" \n\n# Training Configuration\nnum_epochs = 25  # Number of epochs\n\n# Define Dataset Class\nclass ImageAttributeDataset(Dataset):\n    def __init__(self, data_category_pd, img_dir, num_attribute, transform=None):\n        self.img_labels = data_category_pd\n        self.img_dir = img_dir\n        self.transform = transform\n        self.encoders = [LabelEncoder() for _ in range(num_attribute)]\n        \n        # Fit encoders and transform categorical labels into integers\n        for i in range(num_attribute):\n            self.img_labels[f'attr_{i+1}'] = self.img_labels[f'attr_{i+1}'].fillna(-1)\n            valid_indices = self.img_labels[f'attr_{i+1}'] != -1\n            self.img_labels.loc[valid_indices, f'attr_{i+1}'] = self.encoders[i].fit_transform(\n                self.img_labels.loc[valid_indices, f'attr_{i+1}'])\n    \n    def __len__(self):\n        return len(self.img_labels)\n    \n    def __getitem__(self, idx):\n        img_name = os.path.join(self.img_dir, f\"{str(self.img_labels.iloc[idx, 0]).zfill(6)}.jpg\")\n        image = Image.open(img_name).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        attributes = self.img_labels.iloc[idx, 1:].values.astype('int')\n        return image, torch.tensor(attributes)\n\n# Define MultiOutputResNet Model\nclass MultiOutputResNet18(nn.Module):\n    def __init__(self, num_classes_per_attribute):\n        super(MultiOutputResNet18, self).__init__()\n        \n        # Load pretrained ResNet-18\n        self.resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n        \n        # Remove the final fully connected layer and replace with custom heads\n        num_ftrs = self.resnet.fc.in_features\n        self.resnet.fc = nn.Identity()\n        self.attribute_heads = nn.ModuleList([nn.Linear(num_ftrs, num_classes) for num_classes in num_classes_per_attribute])\n\n    def forward(self, x):\n        x = self.resnet(x)\n        outputs = [head(x) for head in self.attribute_heads]\n        return outputs\n\n# Training Function\ndef train_model(Category, data_category_pd):\n    num_attribute = data_category_pd.iloc[0, 2]\n    feature_list = [f'attr_{i+1}' for i in range(num_attribute)]\n    data_category_pd = data_category_pd.reindex(columns=['id'] + feature_list)\n\n    # Define transform\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),  # Standard input size for ResNet-18\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n    \n    dataset = ImageAttributeDataset(data_category_pd, folder_train, num_attribute, transform=transform)\n    \n    # Split dataset into 90% train and 10% validation\n    train_size = int(0.9 * len(dataset))\n    val_size = len(dataset) - train_size\n    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n    # DataLoaders\n    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n    # Model and optimizer\n    num_classes_per_attribute = [len(dataset.encoders[i].classes_) for i in range(num_attribute)]\n    model = MultiOutputResNet18(num_classes_per_attribute)\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    # Training Loop\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n\n        for images, attributes in train_loader:\n            images, attributes = images.to(device), attributes.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n\n            batch_loss = 0\n            valid_count = 0\n\n            for i in range(num_attribute):\n                mask = attributes[:, i] != -1\n                if mask.sum() > 0:\n                    valid_targets = attributes[:, i][mask]\n                    valid_outputs = outputs[i][mask]\n                    loss = criterion(valid_outputs, valid_targets)\n                    batch_loss += loss\n                    valid_count += 1\n\n            if valid_count > 0:\n                batch_loss /= valid_count\n\n            batch_loss.backward()\n            optimizer.step()\n            running_loss += batch_loss.item()\n\n        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")\n\n        # Save model for the epoch\n        model_path = model_path_template.format(Category, epoch+1)\n        torch.save(model.state_dict(), model_path)\n        print(f\"Saved model for Category {Category}, Epoch {epoch+1} at {model_path}\")\n\n    # Save encoders after training\n    encoders_path = encoders_path_template.format(Category)\n    with open(encoders_path, 'wb') as f:\n        pickle.dump(dataset.encoders, f)\n    print(f\"Saved encoders for category: {Category}\")\n\n# Training for each category\ncategory_list = category_attributes['Category']\nfor Category in category_list:\n    data_category_pd = train_attribute.query(f'Category == \"{Category}\"')\n    train_model(Category, data_category_pd)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T03:44:16.537037Z","iopub.execute_input":"2024-11-07T03:44:16.537378Z","iopub.status.idle":"2024-11-07T07:32:31.208885Z","shell.execute_reply.started":"2024-11-07T03:44:16.537342Z","shell.execute_reply":"2024-11-07T07:32:31.207867Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom PIL import Image\nimport pandas as pd\nimport pickle\nimport numpy as np\n\n# main_folder_loc = '/kaggle/input/visual-taxonomy'\n# folder_train = f\"{main_folder_loc}/train_images\"\n# folder_test = f\"{main_folder_loc}/test_images\"\n# train_attribute = pd.read_csv(f\"{main_folder_loc}/train.csv\")\n# test_attribute = pd.read_csv(f\"{main_folder_loc}/test.csv\")\n# category_attributes = pd.read_parquet(f\"{main_folder_loc}/category_attributes.parquet\")\n# model_variant = 'resnet18'\n# main_folder_save_loc = '/kaggle/working'\n# model_path_template = f\"{main_folder_save_loc}/model_{model_variant}_{{}}_epoch{{}}.pth\"  # Model path template for each epoch\n# encoders_path_template = f\"{main_folder_save_loc}/encoders_{model_variant}_{{}}.pkl\" \n\n# Paths\nmain_folder_loc = '/kaggle/input/visual-taxonomy'\nmain_folder_save_loc = '/kaggle/working'\nfolder_test = f\"{main_folder_loc}/test_images\"\ntest_attribute = pd.read_csv(f\"{main_folder_loc}/test.csv\")\ncategory_attributes = pd.read_parquet(f\"{main_folder_loc}/category_attributes.parquet\")\nmodel_variant = 'resnet18'\nmodel_path_template = f\"{main_folder_save_loc}/model_{model_variant}_{{}}_epoch{{}}.pth\"  # Model path template for each epoch\nencoders_path_template = f\"{main_folder_save_loc}/encoders_{model_variant}_{{}}.pkl\"  # Encoder path template\n\n# Specify the epoch to use for inference\nepoch = 24  # Set this to the epoch you want to use\n\n# Define the inference dataset class\nclass InferenceAttributeDataset(Dataset):\n    def __init__(self, data_category_pd, img_dir, transform=None):\n        self.img_labels = data_category_pd\n        self.img_dir = img_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.img_labels)\n    \n    def __getitem__(self, idx):\n        product_id = self.img_labels.iloc[idx, 0]\n        img_name = os.path.join(self.img_dir, f\"{str(product_id).zfill(6)}.jpg\")\n        image = Image.open(img_name).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return product_id, image\n\n# Define MultiOutputResNet Model (ResNet-18)\nclass MultiOutputResNet18(nn.Module):\n    def __init__(self, num_classes_per_attribute):\n        super(MultiOutputResNet18, self).__init__()\n        \n        # Load pretrained ResNet-18\n        self.resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n        \n        # Remove the final fully connected layer and replace it with custom heads\n        num_ftrs = self.resnet.fc.in_features\n        self.resnet.fc = nn.Identity()\n        self.attribute_heads = nn.ModuleList([nn.Linear(num_ftrs, num_classes) for num_classes in num_classes_per_attribute])\n\n    def forward(self, x):\n        x = self.resnet(x)\n        outputs = [head(x) for head in self.attribute_heads]\n        return outputs\n\n# Prediction function\ndef predict_batch(model, images, encoders, num_attribute):\n    with torch.no_grad():\n        outputs = model(images)  # Get logits for each attribute\n    \n    batch_predictions = []\n    \n    for i in range(images.size(0)):  # Loop over batch size\n        predicted_attributes = []\n        \n        for j in range(num_attribute):\n            logits = outputs[j][i]  # Logits for the i-th image and j-th attribute\n            predicted_class = torch.argmax(logits).item()\n            decoded_label = encoders[j].inverse_transform([predicted_class])[0]\n            predicted_attributes.append(decoded_label)\n        \n        batch_predictions.append(predicted_attributes)\n    \n    return batch_predictions\n\n# Inference Pipeline\ncategory_list = category_attributes['Category']\nresults_list = []\n\nfor Category in category_list:\n    print(f\"Inference for Category: {Category}\")\n    \n    # Load test data for the category\n    test_data_category = test_attribute.query(f'Category == \"{Category}\"')\n    train_data_category = train_attribute.query(f'Category == \"{Category}\"')\n    num_attribute = train_data_category.iloc[0, 2]\n\n    # Load the model and encoders for the specified epoch\n    model_path = model_path_template.format(Category, epoch)\n    # model = MultiOutputResNet18([0] * num_attribute) ## this is the correct code. \n    # Load encoders to get num_classes_per_attribute dynamically\n    with open(encoders_path_template.format(Category), 'rb') as f:\n        encoders = pickle.load(f)\n    num_classes_per_attribute = [len(encoder.classes_) for encoder in encoders]\n    \n    # Initialize the model with correct num_classes_per_attribute\n    model = MultiOutputResNet18(num_classes_per_attribute)\n    model.load_state_dict(torch.load(model_path))\n    model.eval()\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n\n    encoders_path = encoders_path_template.format(Category)\n    with open(encoders_path, 'rb') as f:\n        encoders = pickle.load(f)\n\n    # Define the transform\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n    \n    # Initialize Inference Dataset and DataLoader\n    inference_dataset = InferenceAttributeDataset(test_data_category, folder_test, transform=transform)\n    inference_loader = DataLoader(inference_dataset, batch_size=32, shuffle=False, num_workers=4)\n    \n    results = []\n    for product_ids, images in inference_loader:\n        images = images.to(device)\n        batch_predictions = predict_batch(model, images, encoders, num_attribute)\n\n        for i, product_id in enumerate(product_ids):\n            result = {'id': product_id.item()}\n            result.update({f'attr_{j+1}': batch_predictions[i][j] for j in range(num_attribute)})\n            results.append(result)\n    \n    # Convert results to DataFrame and handle missing attributes\n    results_df = pd.DataFrame(results)\n    results_df.insert(1, 'Category', Category)\n    results_df.insert(2, 'len', num_attribute)\n    \n    # Define full set of attribute columns and reindex to ensure consistent columns\n    full_attr = ['id', 'Category', 'len'] + [f'attr_{i+1}' for i in range(10)]\n    results_df = results_df.reindex(columns=full_attr, fill_value='nu')  # Fill missing attributes with 'nu'\n    \n    # Append to results list\n    results_list.append(results_df)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T13:55:00.081296Z","iopub.execute_input":"2024-11-07T13:55:00.081733Z","iopub.status.idle":"2024-11-07T13:56:48.911183Z","shell.execute_reply.started":"2024-11-07T13:55:00.081673Z","shell.execute_reply":"2024-11-07T13:56:48.910059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Merge all category-specific results and save to a single CSV file\nfinal_results = pd.concat(results_list, ignore_index=True)\nfinal_results.to_csv(f\"{main_folder_save_loc}/1_inference_results_{model_variant}_epoch{epoch}.csv\", index=False)\nprint(\"Inference complete and merged results saved.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}