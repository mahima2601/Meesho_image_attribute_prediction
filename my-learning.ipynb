{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9545364,"sourceType":"datasetVersion","datasetId":5815289}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport torch\nimport os\nimport time\nimport random\nimport matplotlib.pyplot as plt\nfrom torch import nn, optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split, Dataset\nfrom PIL import Image\nfrom pathlib import Path \nfrom sklearn.preprocessing import LabelEncoder\nfrom datetime import datetime\nfrom zoneinfo import ZoneInfo","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T18:00:00.999712Z","iopub.execute_input":"2024-11-19T18:00:01.000298Z","iopub.status.idle":"2024-11-19T18:00:01.005200Z","shell.execute_reply.started":"2024-11-19T18:00:01.000266Z","shell.execute_reply":"2024-11-19T18:00:01.004301Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T18:00:02.202213Z","iopub.execute_input":"2024-11-19T18:00:02.202798Z","iopub.status.idle":"2024-11-19T18:00:02.277979Z","shell.execute_reply.started":"2024-11-19T18:00:02.202764Z","shell.execute_reply":"2024-11-19T18:00:02.276972Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"folder_train = \"/kaggle/input/visual-taxonomy/train_images\"\nfolder_test = \"/kaggle/input/visual-taxonomy/test_images\"\ntrain_attribute = pd.read_csv('/kaggle/input/visual-taxonomy/train.csv')\ntest_attribute = pd.read_csv('/kaggle/input/visual-taxonomy/test.csv')\ncategory_attributes = pd.read_parquet(\"/kaggle/input/visual-taxonomy/category_attributes.parquet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T18:00:09.960040Z","iopub.execute_input":"2024-11-19T18:00:09.960612Z","iopub.status.idle":"2024-11-19T18:00:10.666758Z","shell.execute_reply.started":"2024-11-19T18:00:09.960578Z","shell.execute_reply":"2024-11-19T18:00:10.666075Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"/kaggle/input/visual-taxonomy/test_images/000000.jpg\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_attribute","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T11:56:20.875760Z","iopub.execute_input":"2024-11-19T11:56:20.876566Z","iopub.status.idle":"2024-11-19T11:56:20.894382Z","shell.execute_reply.started":"2024-11-19T11:56:20.876534Z","shell.execute_reply":"2024-11-19T11:56:20.893535Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"          id             Category  len      attr_1   attr_2   attr_3  \\\n0          0          Men Tshirts    5     default    round  printed   \n1          1          Men Tshirts    5  multicolor     polo    solid   \n2          2          Men Tshirts    5     default     polo    solid   \n3          3          Men Tshirts    5  multicolor     polo    solid   \n4          4          Men Tshirts    5  multicolor     polo    solid   \n...      ...                  ...  ...         ...      ...      ...   \n70208  70374  Women Tops & Tunics   10  multicolor   fitted  regular   \n70209  70375  Women Tops & Tunics   10      yellow  regular     crop   \n70210  70376  Women Tops & Tunics   10      maroon   fitted     crop   \n70211  70377  Women Tops & Tunics   10         NaN      NaN      NaN   \n70212  70378  Women Tops & Tunics   10        pink     boxy     crop   \n\n            attr_4         attr_5   attr_6      attr_7         attr_8  \\\n0          default  short sleeves      NaN         NaN            NaN   \n1            solid  short sleeves      NaN         NaN            NaN   \n2            solid  short sleeves      NaN         NaN            NaN   \n3            solid  short sleeves      NaN         NaN            NaN   \n4            solid  short sleeves      NaN         NaN            NaN   \n...            ...            ...      ...         ...            ...   \n70208  square neck         casual  printed     default  short sleeves   \n70209   round neck         casual  default     default  short sleeves   \n70210   round neck         casual    solid       solid  short sleeves   \n70211         high            NaN      NaN         NaN  short sleeves   \n70212       v-neck         casual  printed  typography  short sleeves   \n\n                attr_9  attr_10  \n0                  NaN      NaN  \n1                  NaN      NaN  \n2                  NaN      NaN  \n3                  NaN      NaN  \n4                  NaN      NaN  \n...                ...      ...  \n70208  regular sleeves  ruffles  \n70209  regular sleeves  knitted  \n70210  regular sleeves  knitted  \n70211              NaN      NaN  \n70212  regular sleeves      NaN  \n\n[70213 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Category</th>\n      <th>len</th>\n      <th>attr_1</th>\n      <th>attr_2</th>\n      <th>attr_3</th>\n      <th>attr_4</th>\n      <th>attr_5</th>\n      <th>attr_6</th>\n      <th>attr_7</th>\n      <th>attr_8</th>\n      <th>attr_9</th>\n      <th>attr_10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>default</td>\n      <td>round</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>default</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70208</th>\n      <td>70374</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>multicolor</td>\n      <td>fitted</td>\n      <td>regular</td>\n      <td>square neck</td>\n      <td>casual</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>ruffles</td>\n    </tr>\n    <tr>\n      <th>70209</th>\n      <td>70375</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>yellow</td>\n      <td>regular</td>\n      <td>crop</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>default</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>knitted</td>\n    </tr>\n    <tr>\n      <th>70210</th>\n      <td>70376</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>maroon</td>\n      <td>fitted</td>\n      <td>crop</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>knitted</td>\n    </tr>\n    <tr>\n      <th>70211</th>\n      <td>70377</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>high</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>70212</th>\n      <td>70378</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>pink</td>\n      <td>boxy</td>\n      <td>crop</td>\n      <td>v-neck</td>\n      <td>casual</td>\n      <td>printed</td>\n      <td>typography</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>70213 rows × 13 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"test_attribute","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T11:56:30.397996Z","iopub.execute_input":"2024-11-19T11:56:30.398360Z","iopub.status.idle":"2024-11-19T11:56:30.410489Z","shell.execute_reply.started":"2024-11-19T11:56:30.398327Z","shell.execute_reply":"2024-11-19T11:56:30.409701Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"          id             Category\n0          0          Men Tshirts\n1          1          Men Tshirts\n2          2          Men Tshirts\n3          3          Men Tshirts\n4          4          Men Tshirts\n...      ...                  ...\n30200  30484  Women Tops & Tunics\n30201  30485  Women Tops & Tunics\n30202  30486  Women Tops & Tunics\n30203  30487  Women Tops & Tunics\n30204  30488  Women Tops & Tunics\n\n[30205 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Men Tshirts</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Men Tshirts</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Men Tshirts</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Men Tshirts</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Men Tshirts</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30200</th>\n      <td>30484</td>\n      <td>Women Tops &amp; Tunics</td>\n    </tr>\n    <tr>\n      <th>30201</th>\n      <td>30485</td>\n      <td>Women Tops &amp; Tunics</td>\n    </tr>\n    <tr>\n      <th>30202</th>\n      <td>30486</td>\n      <td>Women Tops &amp; Tunics</td>\n    </tr>\n    <tr>\n      <th>30203</th>\n      <td>30487</td>\n      <td>Women Tops &amp; Tunics</td>\n    </tr>\n    <tr>\n      <th>30204</th>\n      <td>30488</td>\n      <td>Women Tops &amp; Tunics</td>\n    </tr>\n  </tbody>\n</table>\n<p>30205 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"category_attributes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T18:07:48.437835Z","iopub.execute_input":"2024-11-19T18:07:48.438654Z","iopub.status.idle":"2024-11-19T18:07:48.476772Z","shell.execute_reply.started":"2024-11-19T18:07:48.438620Z","shell.execute_reply":"2024-11-19T18:07:48.475925Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"              Category  No_of_attribute  \\\n0          Men Tshirts                5   \n1               Sarees               10   \n2               Kurtis                9   \n3        Women Tshirts                8   \n4  Women Tops & Tunics               10   \n\n                                      Attribute_list  \n0  [color, neck, pattern, print_or_pattern_type, ...  \n1  [blouse_pattern, border, border_width, color, ...  \n2  [color, fit_shape, length, occasion, ornamenta...  \n3  [color, fit_shape, length, pattern, print_or_p...  \n4  [color, fit_shape, length, neck_collar, ocassi...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>No_of_attribute</th>\n      <th>Attribute_list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>[color, neck, pattern, print_or_pattern_type, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sarees</td>\n      <td>10</td>\n      <td>[blouse_pattern, border, border_width, color, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Kurtis</td>\n      <td>9</td>\n      <td>[color, fit_shape, length, occasion, ornamenta...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Women Tshirts</td>\n      <td>8</td>\n      <td>[color, fit_shape, length, pattern, print_or_p...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>[color, fit_shape, length, neck_collar, ocassi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"'6'.zfill(6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T19:10:26.713881Z","iopub.execute_input":"2024-11-19T19:10:26.714175Z","iopub.status.idle":"2024-11-19T19:10:26.720868Z","shell.execute_reply.started":"2024-11-19T19:10:26.714147Z","shell.execute_reply":"2024-11-19T19:10:26.719911Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'000006'"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"class ImageAttributeDataset(Dataset):\n    def __init__(self, data_category_pd, img_dir, num_attribute, transform=None):\n        self.img_labels = data_category_pd\n        self.img_dir = img_dir\n        self.transform = transform\n        \n        # Initialize label encoders for each attribute\n        self.encoders = [LabelEncoder() for _ in range(num_attribute)]  \n        \n        # Fit encoders and transform categorical labels into integers, handling NaNs by filling them with -1\n        for i in range(num_attribute):\n            self.img_labels[f'attr_{i+1}'] = self.img_labels[f'attr_{i+1}'].fillna(-1)  # Fill NaN with -1\n            valid_indices = self.img_labels[f'attr_{i+1}'] != -1\n            self.img_labels.loc[valid_indices, f'attr_{i+1}'] = self.encoders[i].fit_transform(\n                self.img_labels.loc[valid_indices, f'attr_{i+1}'])\n    \n    def __len__(self):\n        return len(self.img_labels)\n    \n    def __getitem__(self, idx):\n        # Load image\n        img_name = os.path.join(self.img_dir, f\"{str(self.img_labels.iloc[idx, 0]).zfill(6)}.jpg\")\n        image = Image.open(img_name).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        # Get attribute labels\n        attributes = self.img_labels.iloc[idx, 1:].values.astype('int')\n        \n        return image, torch.tensor(attributes)\n    \n\nclass MultiOutputResNet(nn.Module):\n    def __init__(self, num_classes_per_attribute):\n        super(MultiOutputResNet, self).__init__()\n        \n        # Load pretrained ResNet\n        self.resnet = models.resnet18(pretrained=True)\n        \n        # Remove the final fully connected layer (replace it with our custom heads)\n        num_ftrs = self.resnet.fc.in_features\n        \n        # Create one FC layer per attribute\n        self.resnet.fc = nn.Identity()  # Remove the original fully connected layer\n        self.attribute_heads = nn.ModuleList([nn.Linear(num_ftrs, num_classes) for num_classes in num_classes_per_attribute])\n\n    def forward(self, x):\n        # Extract features using ResNet (without the final FC layer)\n        x = self.resnet(x)\n        \n        # Predict each attribute separately\n        outputs = [head(x) for head in self.attribute_heads]\n        return outputs\n    \nclass InferenceAttributeDataset(Dataset):\n    def __init__(self, data_category_pd, img_dir, transform=None):\n        self.img_labels = data_category_pd\n        self.img_dir = img_dir\n        self.transform = transform\n        \n    \n    def __len__(self):\n        return len(self.img_labels)\n    \n    def __getitem__(self, idx):\n        # Load image\n        product_id = self.img_labels.iloc[idx, 0]\n        img_name = os.path.join(self.img_dir, f\"{str(product_id).zfill(6)}.jpg\")\n        image = Image.open(img_name).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return product_id, image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:09:25.821174Z","iopub.execute_input":"2024-11-19T12:09:25.821834Z","iopub.status.idle":"2024-11-19T12:09:25.833521Z","shell.execute_reply.started":"2024-11-19T12:09:25.821804Z","shell.execute_reply":"2024-11-19T12:09:25.832657Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"num_attribute","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T17:38:23.684952Z","iopub.execute_input":"2024-11-19T17:38:23.685249Z","iopub.status.idle":"2024-11-19T17:38:24.004566Z","shell.execute_reply.started":"2024-11-19T17:38:23.685222Z","shell.execute_reply":"2024-11-19T17:38:24.002206Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnum_attribute\u001b[49m\n","\u001b[0;31mNameError\u001b[0m: name 'num_attribute' is not defined"],"ename":"NameError","evalue":"name 'num_attribute' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"x = [5,8,9]\nfor i in x:\n    print(i)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T17:42:36.955995Z","iopub.execute_input":"2024-11-19T17:42:36.956354Z","iopub.status.idle":"2024-11-19T17:42:36.960949Z","shell.execute_reply.started":"2024-11-19T17:42:36.956323Z","shell.execute_reply":"2024-11-19T17:42:36.960017Z"}},"outputs":[{"name":"stdout","text":"5\n8\n9\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def predict_batch(model, images, encoders, num_attribute):\n    \"\"\"\n    Perform inference on a batch of images to predict attributes.\n    \n    Args:\n    - model (nn.Module): Trained model.\n    - images (torch.Tensor): Batch of images.\n    - encoders (list of LabelEncoder): List of LabelEncoders for each attribute to decode predictions.\n    \n    Returns:\n    - List of lists containing predicted attributes for each image in the batch.\n    \"\"\"\n    # Forward pass through the model\n    with torch.no_grad():\n        outputs = model(images)  # Get outputs from the model (list of logits for each attribute)\n    \n    # List to store predicted attributes for each image\n    batch_predictions = []\n    \n    # Loop over the batch of images\n    for i in range(images.size(0)):  # images.size(0) gives the batch size\n        predicted_attributes = []\n        \n        # For each attribute, get the predicted class and decode it\n        for j in range(num_attribute):  \n            logits = outputs[j][i]  # Logits for the i-th image for the j-th attribute\n            predicted_class = torch.argmax(logits).item()  # Get the predicted class index\n            \n            # Decode the predicted class using the corresponding LabelEncoder\n            decoded_label = encoders[j].inverse_transform([predicted_class])[0]\n            predicted_attributes.append(decoded_label)\n        \n        batch_predictions.append(predicted_attributes)\n    \n    return batch_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:54:32.056232Z","iopub.execute_input":"2024-11-18T18:54:32.056564Z","iopub.status.idle":"2024-11-18T18:54:32.062714Z","shell.execute_reply.started":"2024-11-18T18:54:32.056538Z","shell.execute_reply":"2024-11-18T18:54:32.061731Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"category_list = category_attributes.Category\nresults_list = []\n# model_list = []\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:54:42.097374Z","iopub.execute_input":"2024-11-18T18:54:42.098310Z","iopub.status.idle":"2024-11-18T18:54:42.105544Z","shell.execute_reply.started":"2024-11-18T18:54:42.098272Z","shell.execute_reply":"2024-11-18T18:54:42.104665Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"for Category in category_list:\n    print('running the module for : ', Category)\n    start_time = time.time()\n    data_category_pd  = (train_attribute.query(f'Category == \"{Category}\"'))\n    num_attribute = data_category_pd.iloc[0,2]\n    feature_list = [f'attr_{i+1}'  for i in range(num_attribute)]\n    data_category_pd = data_category_pd.reindex(columns=['id']+  feature_list)\n\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n\n    dataset = ImageAttributeDataset(data_category_pd= data_category_pd, img_dir=folder_train, num_attribute=num_attribute, transform = transform )\n    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n    # Initialize model\n    num_classes_per_attribute = [len(dataset.encoders[i].classes_) for i in range(num_attribute)]\n    model = MultiOutputResNet(num_classes_per_attribute)\n\n    # Move model to GPU if available\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n\n    # Loss function and optimizer\n    criterion = nn.CrossEntropyLoss(reduction='mean')  # Set reduction to 'none' to handle masking\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    end_time = time.time()\n    total_time = (end_time-start_time)/60\n    print(f'time taken for data reading is {total_time}')\n    # Training loop\n    for epoch in range(10):  # Train for 10 epochs\n        model.train()\n        running_loss = 0.0\n        start_time = time.time()\n        print(datetime.now(tz=ZoneInfo('Asia/Kolkata')))\n        for images, attributes in dataloader:\n            images, attributes = images.to(device), attributes.to(device)\n\n            optimizer.zero_grad()\n\n            # Forward pass\n            outputs = model(images)\n\n            total_loss = 0\n            valid_count = 0  # Count valid attributes to average the loss\n\n            # Compute loss for each attribute, ignoring missing values (-1)\n            for i in range(num_attribute):\n                mask = attributes[:, i] != -1  # Mask where the attribute is not NaN (-1)\n                if mask.sum() > 0:  # Only compute loss if there are valid targets\n                    valid_targets = attributes[:, i][mask]  # Filter out invalid targets (-1)\n                    valid_outputs = outputs[i][mask]  # Filter out corresponding outputs\n                    loss = criterion(valid_outputs, valid_targets)#.mean()\n    #                 loss = loss[mask].mean()  # Compute loss only for valid targets\n                    total_loss += loss\n                    valid_count += 1\n\n            # Average the total loss over the number of valid attributes\n            if valid_count > 0:\n                total_loss /= valid_count\n\n            # Backpropagation and optimization\n            total_loss.backward()\n            optimizer.step()\n\n            running_loss += total_loss.item()\n        end_time = time.time()\n        total_time = (end_time-start_time)/60\n\n        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}\")\n        print(f'epoch time taken is {total_time}')\n\n    model_path = f\"/kaggle/working/model_{Category}.pth\"\n    torch.save(model.state_dict(), model_path)\n    model.eval()\n    test_data_category = test_attribute.query(f'Category==\"{Category}\"')\n    # Create the dataset\n    inference_dataset = InferenceAttributeDataset(test_data_category, folder_test , transform=transform)\n    # DataLoader for parallel batch processing\n    inference_loader = DataLoader(inference_dataset, batch_size=32, shuffle=False, num_workers=4)  # num_workers for parallel loading\n#     train_inference_dataset = InferenceAttributeDataset(data_category_pd, folder_train , transform=transform)\n#     train_inference_loader = DataLoader(train_inference_dataset, batch_size=32, shuffle=False, num_workers=4)  # num_workers for parallel loading\n    encoders = dataset.encoders\n    # \n    results = []\n    for product_ids, images in inference_loader:\n        images = images.to(device)  # Move images to GPU/CPU\n        batch_predictions = predict_batch(model, images, encoders, num_attribute)  # Get predictions for the batch\n\n        # Combine product IDs with their predicted attributes\n        for i in range(len(product_ids)):\n            x = batch_predictions[i]\n            results.append({\n                'id': product_ids[i].item(),\n                **{ f'attr_{j+1}':x[j] for j in range(len(x))}\n            })\n\n    # Convert results to a DataFrame and save it\n    results_df = pd.DataFrame(results)\n    results_df.insert(1, 'Category', Category)\n    results_df.insert(2, 'len', num_attribute)\n    full_attr = ['id', 'Category', 'len'] + [f'attr_{i+1}' for i in range(10)]\n    results_df = results_df.reindex(full_attr, axis=1).fillna('nu')\n    results_list = results_list+([results_df])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:54:53.649643Z","iopub.execute_input":"2024-11-18T18:54:53.650010Z"}},"outputs":[{"name":"stdout","text":"running the module for :  Men Tshirts\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 138MB/s] \n","output_type":"stream"},{"name":"stdout","text":"time taken for data reading is 0.015455814202626546\n2024-11-19 00:24:54.591471+05:30\nEpoch 1, Loss: 0.30588590151123835\nepoch time taken is 1.4903095444043477\n2024-11-19 00:26:24.008248+05:30\nEpoch 2, Loss: 0.23285283792045033\nepoch time taken is 0.9788148959477743\n2024-11-19 00:27:22.737580+05:30\nEpoch 3, Loss: 0.2018332122906781\nepoch time taken is 0.9870182275772095\n2024-11-19 00:28:21.959136+05:30\nEpoch 4, Loss: 0.1816017225776848\nepoch time taken is 0.9924176692962646\n2024-11-19 00:29:21.504615+05:30\nEpoch 5, Loss: 0.17333396086305902\nepoch time taken is 0.9925856272379557\n2024-11-19 00:30:21.060186+05:30\nEpoch 6, Loss: 0.1628746918582341\nepoch time taken is 0.9645192702611287\n2024-11-19 00:31:18.931750+05:30\nEpoch 7, Loss: 0.14260212400634037\nepoch time taken is 0.9502082864443461\n2024-11-19 00:32:15.944676+05:30\nEpoch 8, Loss: 0.12100535168786321\nepoch time taken is 0.9623099366823832\n2024-11-19 00:33:13.683704+05:30\nEpoch 9, Loss: 0.11758835749341208\nepoch time taken is 0.9631768226623535\n2024-11-19 00:34:11.474716+05:30\nEpoch 10, Loss: 0.14239459368808752\nepoch time taken is 0.9851915081342061\nrunning the module for :  Sarees\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"time taken for data reading is 0.005498560269673666\n2024-11-19 00:35:24.131574+05:30\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"result_final = pd.concat(results_list)\nresult_final = result_final.sort_values('id')\nresult_final.to_csv('/kaggle/working/cods_results_3.csv')\nresult_final","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}